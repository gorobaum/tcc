\documentclass[brazil]{beamer}
\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usetheme{JuanLesPins}

\title{Comparação de eficiência entre OpenCL e CUDA}
\author{Thiago de Gouveia Nunes}

\begin{document}

\frame{\titlepage}

%-------------------------------------
\section{Tecnologias}
%-------------------------------------

\frame{
  \frametitle{GPGPU}
  É usar uma GPU (Graphics Processing Unit), uma placa criada com foco em Computação Gráfica, 
  para processamento de propósito geral. A arquitetura de uma GPU basicamente é uma região de memória global, um escalonador
  de threads e vários processadores organizados em pequenos grupos. Ela executa usando o método \textbf{SIMD} 
  (Single Instruction, Multiple Data), em que toda thread recebe a mesma instrução mas a executa em dados diferentes.
  Isso faz com que uma GPU resolva problemas altamente paralelizáveis com poucos dados e muito processamento, 
  como uma multiplicação de matrizes, mais rapidamente que CPUs multicore ou sistemas distribuídos.
}

\frame{
  \frametitle{GPGPU}
  Existem 2 frameworks fortes no mercado para GPGPU, o \textbf{CUDA} (Compute Unified Device Architecture) feita pela
  \textit{NVIDIA}, e o \textbf{OpenCL} (Open Computing Language) feito pelo Khronos Group, o mesmo grupo que mantêm o
  OpenGL. O CUDA é 
}

\frame{
  \frametitle{OpenCL}
  O OpenCL é uma framework de programação paralela para sistemas híbridos. Isso quer dizer que podemos rodar 
  aplicações que usam OpenCL tanto em CPUs como em GPUs.
  OpenCL foi uma iniciativa da Apple, e depois sofreu várias melhorias por times de várias empresas, entre elas Intel 
  e Nvidia. OpenCL pode ser usado em C e C++. %Colocar o que é OpenCL e SIMD
}

\frame{
  \frametitle{CUDA}
  CUDA é uma plataforma para programação paralela em GPUs desenvolvida pela Nvidia. Ela suporta C, C++, Java, Python, Fortran, etc. % referencia, explicar melhor as diferencas entre opencl
}

%-------------------------------------
\section{Comparação entre as abstrações}
%-------------------------------------

\frame{
  \frametitle{Termos Técnicos}
  A explicação dos termos técnicos que serão usados:
  \begin{itemize}
    \item[Kernel] Função que será executada em cada processador da placa de vídeo.
    \item[Host]   Programa que será executado na CPU e tem a função de preparar o ambiente para o kernel e rodá-lo na GPU.
    \item[SIMD]   \textit{Single Instrution, Multiple Data.} Os processadores das GPUs são desse tipo. Cada um recebe o mesmo código, mas roda usando dados diferentes.
    \item[Device]   GPU ou CPU.
    \item[CU]     \textit{Computer Unit}, um processador.
    \item[PE]     \textit{Processing Element}, um core do processador.
  \end{itemize} % colocar referencias, indicar palavras chave e seus significados, estrutura da placa de video.
}

%-------------------------------------
\subsection{OpenCL}
%-------------------------------------

\frame{
  \frametitle{Modelos}
  OpenCL usa uma hierarquia de 4 modelos:
  \begin{enumerate}
    \item Modelo de Plataforma
    \item Modelo de Execução
    \item Modelo de Memória
    \item Modelo de Programação
  \end{enumerate}
}

\frame{
  \frametitle{Modelo de Plataforma}
  O modelo de plataforma é responsável por representar o Host ligado a um ou mais Devices, cada com um ou mais CU's, cada CU com um ou mais PE's.
  A aplicação do OpenCL fica no Host, que é responsável por direcionar os kernel's para os PE's em cada Device
}

\frame{
  \frametitle{Modelo de Execução}
  O modelo de execução representa o programa que roda no Host, e todos os Kernel's. O host prepara um contexto para a execução do kernel e o roda. \\
  Quando o Kernel começa a executar, um espaço de indices é criado, onde cada indice representa uma cópia do kernel rodando. Esse espaço pode ter dimensão 1, 2 ou 3.
}

\frame{
  \frametitle{Contexto}
  O contexto onde o kernel é executado tem os seguintes recursos:
  \begin{itemize}
    \item Devices
    \item Kernels
    \item Program Objects: O código fonte do kernel.
    \item Memory Objects: Objetos que representão a memória que será modificada pelo kernel. Tanto o host como o kernel tem acesso a ela.
    \item Command-Queue: Fila que cuida da ordem em que tudo será executado num device.
  \end{itemize}
}

\frame{
  \frametitle{Modelo de Memória}
  Cada instância do kernel tem acesso a 4 tipos de memórias distintas:
  \begin{enumerate}
     \item Global Memory  - Toda e qualquer instância de um kernel tem acesso a essa memória.
     \item Constat Memory - Memória que permanece fixa ao andar da execução.
     \item Local Memory   - Região da memória dividida pelos kernel's de um mesmo CU.   
     \item Private Memory - Região privada para cada instância de um kernel.
   \end{enumerate} 
}

\frame{
  \frametitle{Modelo de Programação}
  O OpenCL suporpa dois modelos de programação, o Data Parallel e o Task Parallel.
  \begin{enumerate}
    \item Data Parallel - É o modelo padrão do OpenCL, cria várias instâncias iguais do kernel, cada uma recebendo argumentos diferentes.
    \item Task Parallel - Nesse modelo, cada kernel tem só uma instância, e o programador tem que usar outros objetos ( Ex: vetores ) para expressar o paralelismo do kernel.
  \end{enumerate}
}

%-------------------------------------
%\subsection{CUDA}
%-------------------------------------

%TODO

%-------------------------------------
\section{Comparação de Performance}
%-------------------------------------

\frame{
  \frametitle{Ideia}
  Para comparar a performance das duas plataformas, a ideia inicial é usar dois kernel's, um para comparar o tempo 
  que cada um leva pra computar uma operação com muita movimentação de memória, e outro com alto processamento. 
  Os kernel's em OpenCL já estão prontos e os de CUDA estão em andamento.
} % colocar termos como memory bound, falar de memory x computings

\frame{
  \frametitle{Kernel Memory bound}
  Para comparar a cópia de memória, usamos um kernel que usa a GPU para copiar uma matriz de double em outra.
} % como fazer o profiling e ver preempção ( comparação casa x bigfoot )

\frame{
  \frametitle{Kernel Computing bound}
  Para comparar o processamento, usamos um kernel que usa a GPU multiplicar duas matrizes de doubles.
  Obtemos o tempo real do processamento tirando o tempo de execução do kernel memory bound do tempo desse kernel.
} % comparar o ptx, colocar o código dos kernels, comparar o tamanho, 

\end{document}
