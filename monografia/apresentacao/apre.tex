\documentclass[brazil]{beamer}
\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usetheme{JuanLesPins}

\title{Comparação de eficiência entre OpenCL e CUDA}
\author{Thiago de Gouveia Nunes}

\begin{document}

\frame{\titlepage}

%-------------------------------------
\section{Tecnologias}
%-------------------------------------

\frame{
  \frametitle{GPGPU}
  É usar uma GPU (Graphics Processing Unit), uma placa criada com foco em Computação Gráfica, 
  para processamento de propósito geral. A arquitetura de uma GPU basicamente é uma região de memória global, um escalonador
  de threads e vários processadores organizados em pequenos grupos. Ela executa usando o método \textbf{SIMD} 
  (Single Instruction, Multiple Data), em que toda thread recebe a mesma instrução mas a executa em dados diferentes.
  Isso faz com que uma GPU resolva problemas altamente paralelizáveis com poucos dados e muito processamento, 
  como uma multiplicação de matrizes, mais rapidamente que CPUs multicore ou sistemas distribuídos.
}

\frame{
  \frametitle{GPGPU}
  Existem 2 linguagens fortes no mercado para GPGPU, o \textbf{CUDA} (Compute Unified Device Architecture) feita pela
  \textit{NVIDIA}, e o \textbf{OpenCL} (Open Computing Language) feito pelo Khronos Group, o mesmo grupo responsável pelo
  OpenGL. O objetivo do trabalho é comparar esses dois frameworks através de testes de desempenho e comparação nas abstrações
  feitas para utilizar a GPU.
}

\frame{
  \frametitle{OpenCL}
  O OpenCL é uma linguagem de programação paralela para sistemas híbridos. Ele da suporte para sistemas baseados tanto em GPU, CPU ou
  outros processadores. O OpenCL é open source e foi uma iniciativa da Apple, que depois sofreu melhorias feitas por times de várias 
  empresas, dentre elas Intel, IBM e NVIDIA. OpenCL pode ser usado em conjunto tanto com C quanto com o C++.
}

\frame{
  \frametitle{CUDA}
  CUDA é uma linguagem para programação paralela em GPUs desenvolvida pela NVIDIA. Atualmente só existe 1 compilador
  de CUDA para placas NVIDIA, o \textit{nvcc}. O CUDA é proprietário. Ela suporta C e C++ e existem wrappers para 
  Java, Python e Fortran.
}

\frame{
  \frametitle{GPU}
  Antes de entrar na comparação entre as linguagens, vamos discutir sobre a GPU usada para os testes, uma GeForce GTX 460 SE.
  % COLOCAR IMAGEM DA	 GEFORCE 460.
}

%-------------------------------------
\section{Comparação entre as linguagens}
%-------------------------------------

\frame{
  \frametitle{Termos Técnicos}
  A explicação dos termos técnicos que serão usados:
  \begin{itemize}
    \item[Kernel] Função que será executada em cada processador da placa de vídeo.
    \item[Host]   Programa que tem a função de preparar o ambiente para o kernel e iniciá-lo na GPU.
    \item[SIMD]   \textit{Single Instrution, Multiple Data}. As GPU executam suas tarefas usando esse paradigma.
    \item[Device]   Hardware onde os kernels serão executados, normalmente uma GPU ou CPU.
  \end{itemize}
}

\frame{
  \frametitle{Semelhanças}
  Alguns elementos são iguais para as duas linguagens.
  \begin{itemize}
    \item Para iniciar a execução num device, é necessario que um programa chamado de host inicie o ambiente de execução na GPU.
    \item As threads executando no device são identificadas por indices. Esses indices podem ter até 3 dimensões.
    \item As threads são agrupadas em conjuntos antes de serem enviadas para execução no device, e esses conjuntos são escalonados, 
      não as threads. Esses conjuntos, assim como os indices, também podem ter até 3 dimensões.
    \item A alocação e preenchimento da memória no device é controlada pelo host.
  \end{itemize}
}

\frame{
  \frametitle{Semelhanças}
  \begin{itemize}
    \item A execução dos kernels podem ser síncronas ou assíncronas com o a execução do host. É possível criar barreiras no host
      que esperam algum evento no device.
    \item As duas linguagens definem versões tanto para os hardwares como para as APIs que elas usam e essas versões definem
      quais operações estão disponiveis naquele hardware ou API. Isso é importante pois cria uma retrocompatibilidade, já que
      as placas da NVIDIA emulam funcionalidades que elas não tem, a custo de desempenho. 
  \end{itemize}
}

\frame{
  \frametitle{Semelhanças}
  \begin{itemize}
      \item Existem 4 locais diferentes para a memória que é enviada para o device:
        \begin{enumerate}
         \item Global Memory  - Toda e qualquer thread tem acesso a essa memória.
         \item Constat Memory - Memória que permanece fixa ao andar da execução.
         \item Local Memory   - Região da memória dividida pelas threads de um mesmo SM.   
         \item Private Memory - Região privada para cada thread.
       \end{enumerate} 
  \end{itemize}
}

\frame{
  \frametitle{Diferenças - Plataforma}
  No OpenCL, a inicialização de um device é de responsabilidade do programador. Ele deve criar uma plataforma (objeto que
  representa um host e um ou mais devices), identificar os devices no computador e associá-los à plataforma, depois
  criar um contexto relacionando o kernel a ser executado, os devices onde ele deve executar e uma fila de execução que será
  usada para enviar dados do device para o host e vice versa. No CUDA, esse processo é feito por diretivas, que são usadas
  para enviar e receber os dados do device e iniciar a execução do kernel. Toda a parte de identificar e iniciar um device
  é feita em background pelo CUDA no inicio da execução do host, mas é possível escolher em qual device o kernel será
  executado.
}

\frame{
  \frametitle{Diferenças - Plataforma}
  No OpenCL existem 2 tipos de execução diferentes:
  \begin{enumerate}
    \item Data Parallel - É o modelo padrão do OpenCL, cria várias instâncias iguais do kernel, cada uma recebendo argumentos diferentes.
    \item Task Parallel - Nesse modelo, cada kernel tem só uma instância, e o programador tem que usar outros objetos 
      para expressar o paralelismo do kernel. Um exemplo de como o programador pode fazer isso é utilizar os tipo
      vetoriais implementados no device ou executar várias tasks assíncronamente no device.
  \end{enumerate}
}

\frame{
  \frametitle{Diferenças - Execução}
  O modelo de execução as duas linguagens é bem parecido já que ele é limitado pela execução da GPU. Nas GPUs NVIDIA,
  as threads são executadas em grupos de 8, chamados de \textit{warp}, e esses warps são agrupados em blocos, com no máximo
  1024 threads. Os blocos são escalonados para execução nos SM. \\
  Assim, as duas linguagens definem objetos parecidos com os blocos para organizarem as threads. No OpenCL, esse objeto
  é chamado de \textit{work-group}, e no CUDA de \textit{block}. 
}

%-------------------------------------
\section{Comparação de Performance}
%-------------------------------------

\frame{
  \frametitle{Ideia}
  Para comparar a performance das duas linguagens foram usados dois tipos de kernel, um em que o desempenho está ligado ao acesso a
  memória (memory bound) e outro que está ligado à velocidade de processamento (compute bound).
}

\frame{
  \frametitle{Kernel Memory bound} 
  Memory bound é um gargalo comum em GPGPU já que os dados vêm para a GPU através de um barramento PCI-Express, normalmente
  utilizado por outras aplicações, criando um atraso no recebimento dos dados. Com os dados dentro da GPU, ainda temos o problema
  de escalonar o acesso à memória a vários SM diferentes.
  Para comparar a memória, foi usado um kernel que faz a cópia de uma matriz de floats para outras.
} 


\begin{frame}[fragile]
  \frametitle{Kernel Memory bound}

\end{frame}

\frame{
  \frametitle{Kernel Compute bound}
  Minimizar o custo do processamento é importante em GPUs já que estamos rodando nossas aplicações em centenas de
  processadores ao mesmo tempo, fazendo o impacto de uma pequena melhoria no tempo de execução uma centena de vezes maior.
  Para comparar o processamento, usamos um kernel que multiplica duas matrizes de doubles e guarda o valor numa terceira.
  Obtemos o tempo real do processamento tirando o tempo de execução do kernel memory bound do tempo desse kernel.
}

\begin{frame}[fragile]
  \frametitle{Kernel Compute bound}

\end{frame}

\frame{Estatisticas}

\frame{
  \frametitle{Explicação dos PTX}
  Para melhorar a compatibilidade dos programas rodando em GPUs diferentes, a NVIDIA implementou uma máquina virtual, a Parallel Thread Execution (PTX). 
  Antes de ter seu binário compilado, todo kernel, independende da linguagem, é précompilado para um arquivo .ptx que será executado na máquina virtual. 
  Observando os arquivos PTX resultantes da compilação é possível identificar qual a diferença para a GPU das abstrações das linguagens e quais os impactos 
  disso no desempenho dos programas.
}

\begin{frame}[fragile]
  \frametitle{Comparação dos PTX}
  Pelos .ptx é possível verificar algumas das diferenças entre as abstrações das linguagens:
  \begin{enumerate}
    \item Ao calcular o indice global de uma thread, o OpenCL usa um registrador a mais, que é usado para identificar o kernel que a thread faz parte. O CUDA não
      precisa dessa informação a mais pois só é possivel rodar um kernel por aplicação por vez.
    \item O OpenCL faz mais leituras da memória padrão que o CUDA. Isso é visivel nos .ptx dos kernels process bound. A cada iteração do loop o OpenCL
      carrega todos os paramêtros para seus registradores, enquanto o CUDA carrega somente um paramêtro, o necessário para validar o próximo passo do loop.
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{Comparação dos PTX}
  Pelos resultados dos .ptx, o compilador para PTX do CUDA é mais otimizado que o do OpenCL. Ao acessar uma posição de memória dentro de um loop, o compilador
  do CUDA faz todos os cálculos que não serão afetados pelos passos do loop fora dele, e usa esses valores em conjunto com o passo do loop para determinar a
  posição que deve ser lida da memória global. Já o OpenCL lê a cada passo esses valores constantes da memória global, aumentando o tempo de execução com
  leituras custosas à memória.
\end{frame}

\end{document}
