\section{Atividades Realizadas}
\subsection{Comparação das abstrações}
Podemos ver que as abstrações de execução das duas linguagens são bem parecidas. Cada uma delas tem tem uma abstração
para threads rodando o kernel ( \textit{work-item} para o OpenCL e \textit{CUDA threads} para o CUDA). Nas duas linguagens
existe uma abstração para dispor as threads num conjunto de até 3 dimensões. 

Toda thread, em ambas as linguagens, tem um ID único que a identifica em relação a todas as threads em execução (o ID global) 
e um ID que a identifica unicamente dentro de um bloco (o ID local). O ID global é uma combinação do ID local com o ID do bloco. 
É comum usar o ID das threads para identificar quais os dados que ela irá receber. No exemplo desse trabalho, o ID 
global das threads é usado para determinar qual posição das matrizes ela irá usar nas suas operações. 

Como os processadores das GPUs estão agrupados em vários streaming multiprocessors, as linguagens criam uma organização lógica para
separar as threads em blocos (\textit{work-group} no OpenCL e \textit{block} no CUDA). A execuçãi dos blocos devem ser independentes entre
si, ou seja, o bloco A pode ser escalonado antes do bloco B ou vice versa e o resultao final deve ser o mesmo. Dado isso, o escalonador
irá escalonar primeiramente os blocos e só depois as threads são escalonadas dentro dos blocos. Threads dentro
do mesmo bloco compartilham recursos como o acesso a memória, um escalonador espera um número de requisições suficientemente grande 
antes de tentar acessar a memória global, tentando minimizar o número de acessos pelo bloco; todas as threads de um mesmo bloco
compartilham uma região de memória compartilhada e um conjunto de processadores para funções especiais, como por exemplo
rasterizações ou funções geeométricas. 

Os blocos são agrupados em um conjunto maior que determina o número total de threads por kernel sendo executado. 
No OpenCL, esse conjunto se chama \textit{NRange} e no CUDA \textit{Grid}. O OpenCL cria um NDRange por execução do kernel
e as dimensões do NDRange e dos work-groups dentro dele são iguais. O espaço de indices das threads de um NDRange pode começar 
tanto de zero quanto de um número definido pelo usuário, facilitanto operações em posições de memória deslocadas dentro 
do espaço de memória do problema.
	
Já no CUDA, os Grids podem ter sua dimensão diferente da dimensão dos blocks. O espaço de indices das threads é limitado a começar 
do zero e existe um limite de 1024 threads por block, resultado da divisão de memória que o CUDA faz para cada block. A execução
de um kernel é representada por um único grid.
\\

Sobre a memória, as duas linguagens deixam a criação e alocação da memória para o \textit{host}. Cada uma delas define uma maneira
diferente de tratar a memória, no CUDA a memória é tratada de maneira semelhante ao C. Por exemplo, para alocar um vetor de inteiros
primeiro devemos declarar um ponteiro para inteiro como no C, e depois alocar o tamanho dele dentro da GPU e copiar os dados da 
memória do \textit{host} para a memória do \textit{device} usando diretivas do CUDA. O OpenCL cria objetos de memória que serão
mapeados para a memória do \textit{device}. As operações de leitura e escrita nesses objetos são feitos através de uma fila de 
execução.
\subsection{Comparação de eficiencia}
\subsubsection{Como fazer a comparação?}
\subsubsection{Montagem dos kernels}
\subsection{Comparação entre os arquivos .ptx}
